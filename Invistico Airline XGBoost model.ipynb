{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yugMU9MjJtBl"
   },
   "source": [
    "# Activity: Build an XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzWqJunmJotv"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this activity, you’ll build on the skills and techniques you learned in the decision tree and random forest lessons to construct your own XGBoost classification model. The XGBoost model is a very powerful extension of decision trees, so having a strong working familiarity with this process will strengthen your skills and resume as a data professional.\n",
    "\n",
    "This activity is a continuation of the airlines project in which you built decision tree and random forest models. You will use the same data, but this time you will train, tune, and evaluate an XGBoost model. You’ll then compare the performance of all three models and decide which model is best. Finally, you’ll explore the feature importances of your model and identify the features that most contribute to customer satisfaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTVinL1hJqoy"
   },
   "source": [
    "## Step 1: Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDIRpqkZJ4S8"
   },
   "source": [
    "### Import packages\n",
    "\n",
    "Begin with your import statements. First, import `pandas`, `numpy`, and `matplotlib` for data preparation. Next, import scikit-learn (`sklearn`) for model preparation and evaluation. Then, import `xgboost`, which provides the classification algorithm you'll implement to formulate your predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1nDjAJPa4lVZ"
   },
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "\nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/puteriirenealiaabdulhadi/Github/Data-Science/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <FBD6AEF9-AFAB-39D7-B881-755157DA0497> /Users/puteriirenealiaabdulhadi/Github/Data-Science/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file)\"]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# This is the classifier\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# This is the function that helps plot feature importance \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_importance\n",
      "File \u001b[0;32m~/Github/Data-Science/.venv/lib/python3.9/site-packages/xgboost/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracker  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collective, dask\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     Booster,\n\u001b[1;32m     10\u001b[0m     DataIter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     build_info,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/Github/Data-Science/.venv/lib/python3.9/site-packages/xgboost/tracker.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntEnum, unique\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional, Union\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LIB, _check_call, make_jcargs\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_family\u001b[39m(addr: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get network family from address.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Github/Data-Science/.venv/lib/python3.9/site-packages/xgboost/core.py:269\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m _LIB \u001b[38;5;241m=\u001b[39m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m        return value from API calls\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Github/Data-Science/.venv/lib/python3.9/site-packages/xgboost/core.py:222\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib_success:\n\u001b[1;32m    221\u001b[0m         libname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(lib_paths[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124mXGBoost Library (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) could not be loaded.\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124mLikely causes:\u001b[39m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124m  * OpenMP runtime is not installed\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124m    - vcomp140.dll or libgomp-1.dll for Windows\u001b[39m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124m    - libomp.dylib for Mac OSX\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124m    - libgomp.so for Linux and other UNIX-like OSes\u001b[39m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124m    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\u001b[39m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[38;5;124m  * You are running 32-bit Python on a 64-bit OS\u001b[39m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[38;5;124mError message(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos_error_list\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m     _register_log_callback(lib)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(ver: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n",
      "\u001b[0;31mXGBoostError\u001b[0m: \nXGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed\n    - vcomp140.dll or libgomp-1.dll for Windows\n    - libomp.dylib for Mac OSX\n    - libgomp.so for Linux and other UNIX-like OSes\n    Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n\n  * You are running 32-bit Python on a 64-bit OS\n\nError message(s): [\"dlopen(/Users/puteriirenealiaabdulhadi/Github/Data-Science/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: @rpath/libomp.dylib\\n  Referenced from: <FBD6AEF9-AFAB-39D7-B881-755157DA0497> /Users/puteriirenealiaabdulhadi/Github/Data-Science/.venv/lib/python3.9/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file)\"]\n"
     ]
    }
   ],
   "source": [
    "# Import relevant libraries and modules.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# This is the classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# This is the function that helps plot feature importance \n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This displays all of the columns, preventing Juptyer from redacting them.\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# This module lets us save our models once we fit them.\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKylHziGzY3X"
   },
   "source": [
    "### Load the dataset\n",
    "\n",
    "To formulate your model, `pandas` is used to import a csv of airline passenger satisfaction data called `Invistico_Airline.csv`. This DataFrame is called `airline_data`. As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ebqpNcm4BDH"
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO IMPORT YOUR DATA. \n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "airline_data = pd.read_csv('Invistico_Airline.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXvtnFn5oBIG"
   },
   "source": [
    "### Display the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bg_6M3IRgMU"
   },
   "source": [
    "Examine the first 10 rows of data to familiarize yourself with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWu8u19C2sn1"
   },
   "outputs": [],
   "source": [
    "# Display the first ten rows of data.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADuU5IWb04cu"
   },
   "source": [
    "### Display the data type for each column\n",
    "\n",
    "Next, observe the types of data present within this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABDz9TMu04cv"
   },
   "outputs": [],
   "source": [
    "# Display the data type for each column in your DataFrame.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzQNmlZ75e_Y"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Recall the methods for exploring DataFrames.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWXkObsg5gzd"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Recall a property of a `pandas` DataFrame that allows you to view the data type for each column.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU9z6ufC5n58"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call `.dtypes` on your DataFrame `airline_data` to view the data type of each column.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Albdy39HZwQT"
   },
   "source": [
    "**Question:** Identify the target (or predicted) variable for passenger satisfaction. What is your initial hypothesis about which variables will be valuable in predicting satisfaction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymp_LP1bVz-q"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zz8claq0Swi"
   },
   "source": [
    "## Step 2: Model preparation\n",
    "\n",
    "Before you proceed with modeling, consider which metrics you will ultimately want to leverage to evaluate your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZkWks-m04cx"
   },
   "source": [
    "**Question:** Which metrics are most suited to evaluating this type of model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWVDNggPeeiE"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kgPx_MP0cuc"
   },
   "source": [
    "### Prepare your data for predictions\n",
    "\n",
    "You may have noticed when previewing your data that there are several non-numerical variables (`object` data types) within the dataset.\n",
    "\n",
    "To prepare this DataFrame for modeling, first convert these variables into a numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03d00d56"
   },
   "outputs": [],
   "source": [
    "# Convert the object predictor variables to numerical dummies.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlxKL4az04cy"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about feature engineering](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/5mEqu/introduction-to-feature-engineering).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diCw9tRr04cy"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Use the `pandas` function for transforming categorical data into \"dummy\" variables.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yE00Fex04cy"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Use the `get_dummies()` function on your DataFrame `airline_data` to create dummies for the categorical variables in your dataset. Note that your target variable will also need this treatment.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbDWO7ai04cy"
   },
   "source": [
    "### Isolate your target and predictor variables\n",
    "Separately define the target variable (`satisfaction`) and the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xO46EzS8oBIG"
   },
   "outputs": [],
   "source": [
    "# Define the y (target) variable.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Define the X (predictor) variables.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SiBf2fH04cz"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about splitting your data into x and y](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/ozK9K/build-a-decision-tree-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fISCsPN04cz"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "In `pandas`, use square brackets `[]` to subset your DataFrame by specifying which column(s) to select. Also, quickly subset a DataFrame to exclude a particular column by using the `drop()` function and specifying the column to drop.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frf-kwtY04cz"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "In this case, your target variable was split into two columns from the dummy split. Be sure to include only the column which assigns a positive (i.e., \"satisfied\") outcome as 1.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ-wo4UOoBII"
   },
   "source": [
    "### Divide your data \n",
    "\n",
    "Divide your data into a training set (75% of the data) and test set (25% of the data). This is an important step in the process, as it allows you to reserve a part of the data that the model has not used to test how well the model generalizes (or performs) on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pO2AdPR7oBIJ"
   },
   "outputs": [],
   "source": [
    "# Perform the split operation on your data.\n",
    "# Assign the outputs as follows: X_train, X_test, y_train, y_test.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgY9icEY2mKn"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about splitting your data between a training and test set](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/ozK9K/build-a-decision-tree-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUmzKZUU2mKp"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "To perform the splitting, call the function in the `model_selection` module of `sklearn` on the features and target variable.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORy1MNR62mKq"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call the `train_test_split()` function, passing in both `features` and `target`, while configuring the appropriate `test_size`. Assign the output of this split as `X_train`, `X_test`, `y_train`, `y_test`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY0rAjlZAheh"
   },
   "source": [
    "## Step 3: Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6VpTiBeGvyO"
   },
   "source": [
    "### \"Instantiate\" your XGBClassifer\n",
    "\n",
    "Before you fit your model to your airline dataset, first create the XGB Classifier model and define its objective. You'll use this model to fit and score different hyperparameters during the GridSearch cross-validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IV1ISYSA04c0"
   },
   "outputs": [],
   "source": [
    "# Define xgb to be your XGBClassifier.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkPZLxYU04c0"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about constructing a classifier model from `xgboost`](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/njRAP/build-an-xgboost-model-with-python).</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9C5xlEx04c0"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Note that the target variable in this case is a binary variable. </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owKHj88104c1"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Use the `XGBClassifier()` from `xgboost`. Set the objective as `binary:logistic`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7kUCHb504c1"
   },
   "source": [
    "### Define the parameters for hyperparameter tuning\n",
    "\n",
    "To identify suitable parameters for your `xgboost` model, first define the parameters for hyperparameter tuning. Specifically, consider tuning `max_depth`, `min_child_weight`, `learning_rate`, `n_estimators`, `subsample`, and/or `colsample_bytree`.\n",
    "\n",
    "Consider a more limited range for each hyperparameter to allow for timely iteration and model training. For example, using a single possible value for each of the six hyperparameters listed above will take approximately one minute to run on this platform.\n",
    "\n",
    "```\n",
    "{\n",
    "    'max_depth': [4],\n",
    "    'min_child_weight': [3],\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': [5],\n",
    "    'subsample': [0.7],\n",
    "    'colsample_bytree': [0.7]\n",
    "}\n",
    "```\n",
    "\n",
    "If you add just one new option, for example by changing `max_depth: [4]` to `max_depth: [3, 6]`, and keep everything else the same, you can expect the run time to approximately double. If you use two possibilities for each hyperparameter, the run time would extend to ~1 hour. \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjO_QnJz04c1"
   },
   "outputs": [],
   "source": [
    "# Define parameters for tuning as `cv_params`.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kw9awgVE04c1"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about hyperparameter tuning using GridSearch cross-validation](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/afopk/tune-a-decision-tree).</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atDAefeG04c1"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Consider a range of values for each parameter, similar to what you observed in the lesson. </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zzXqOgf04c1"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Define these parameters using a Python dictionary in the following format: `{'parameter1': [range,of,values]}`</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LA1VKyV04c2"
   },
   "source": [
    "**Question:** What is the likely effect of adding more estimators to your GridSearch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuIY2Or4ZV_I"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wX7X5kVN04c2"
   },
   "source": [
    "### Define how the models will be evaluated\n",
    "\n",
    "Define how the models will be evaluated for hyperparameter tuning. To yield the best understanding of model performance, utilize a suite of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orCI7GMj04c2"
   },
   "outputs": [],
   "source": [
    "# Define your criteria as `scoring`.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P1-imU504c2"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Recall what you've learned about [using metric evaluation](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/afopk/tune-a-decision-tree) to determine the metrics you include.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpqJc3aM04c2"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Consider what you've learned about the limitations of only including a single metric, such as `accuracy`. </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_SLHKSR04c2"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Define metrics which balance the false positives and false negatives in binary classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeAqRwg704c2"
   },
   "source": [
    "### Construct the GridSearch cross-validation \n",
    "\n",
    "Construct the GridSearch cross-validation using the model, parameters, and scoring metrics you defined. Additionally, define the number of folds and specify *which metric* from above will guide the refit strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bu_GHb2N04c3"
   },
   "outputs": [],
   "source": [
    "# Construct your GridSearch.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FopWeHuF04c3"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Recall what you've learned about constructing a GridSearch for [cross-validation](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/W4vAW/verify-performance-using-validation).</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEGQZkPr04c3"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Balance the time spent on validation with the number of folds you choose. </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vomsOetH04c3"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Choose the refit method which simultaneously balances false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9K4LvKdx04c3"
   },
   "source": [
    "### Fit the GridSearch model to your training data\n",
    "\n",
    "If your GridSearch takes too long, revisit the parameter ranges above and consider narrowing the range and reducing the number of estimators.\n",
    "\n",
    "**Note:** The following cell might take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHXvHPNW04c3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit the GridSearch model to training data\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YS06KhTSoBIM"
   },
   "source": [
    "**Question:** Which optimal set of parameters did the GridSearch yield?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLkpTn0vZ-qa"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOBvfCNeoBIM"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Recall what you've learned about the result of the GridSearch.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzT16WHjoBIM"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Once you've fitted the GridSearch model to your training data, there will be an attribute to access which yields to the optimal parameter set.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IILInxLYoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Access the `best_params_` attribute from your fitted model. </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5EFtZfXoBIN"
   },
   "source": [
    "### Save your model for reference using `pickle`\n",
    "\n",
    "Use the `pickle` library you've already imported to save the output of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1yjbFhJ04c4"
   },
   "outputs": [],
   "source": [
    "# Use `pickle` to save the trained model.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74v1TcAz04c4"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about \"pickling\" prior models](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/FSnam/build-and-validate-a-random-forest-model-using-a-validation-data-set).</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-xt3jro04c5"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "The model to be pickled is the fitted GridSearch model from above. </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiEBmZUI04c5"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call `pickle.dump()`, reference the fitted GridSearch model, and provide a name for the pickle file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgV_6xAQAvgg"
   },
   "source": [
    "## Step 4: Results and evaluation\n",
    "\n",
    "### Formulate predictions on your test set\n",
    "\n",
    "To evaluate the predictions yielded from your model, leverage a series of metrics and evaluation techniques from scikit-learn by examining the actual observed values in the test set relative to your model's prediction.\n",
    "\n",
    "First, use your trained model to formulate predictions on your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUEgzQW_6oMV"
   },
   "outputs": [],
   "source": [
    "# Apply your model to predict on your test data. Call this output \"y_pred\".\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2vRT5XeoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Recall what you've learned about creating predictions from trained models.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo1E7RjtoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Use the fitted GridSearch model from your training set and predict the predictor variables you reserved in the train-test split.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azSq51xXoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call `predict()` on your fitted model and reference `X_test` to create these predictions.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPswDdr1oBIO"
   },
   "source": [
    "### Leverage metrics to evaluate your model's performance\n",
    "\n",
    "Apply a series of metrics from scikit-learn to assess your model. Specifically, print the accuracy score, precision score, recall score, and f1 score associated with your test data and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INf2Rd_MoBIP"
   },
   "outputs": [],
   "source": [
    "# 1. Print your accuracy score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# 2. Print your precision score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# 3. Print your recall score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# 4. Print your f1 score.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEgb0a2YoBIP"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about model evaluation for detail on these metrics](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/njRAP/build-an-xgboost-model-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oT143KsSoBIP"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Use the function in the `metrics` module in `sklearn` to compute each of these metrics.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BECv4a2toBIP"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call `accuracy_score()`, `precision_score()`, `recall_score()`, and `f1_score()`, passing `y_test` and `y_pred` into each.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDx7rrdNoBIP"
   },
   "source": [
    "**Question:** How should you interpret your accuracy score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWUqly7WbVEg"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QirKWngCah9v"
   },
   "source": [
    "**Question:** Is your accuracy score alone sufficient to evaluate your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApnZ_M5pbdC9"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evpAa_4noBIP"
   },
   "source": [
    "**Question:** When observing the precision and recall scores of your model, how do you interpret these values, and is one more accurate than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew7L0yIubmGb"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ghkTwSUoBIP"
   },
   "source": [
    "**Question:** What does your model's F1 score tell you, beyond what the other metrics provide?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qE996PP6by1l"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNzDfI3RoBIQ"
   },
   "source": [
    "### Gain clarity with the confusion matrix\n",
    "\n",
    "Recall that a **confusion matrix** is a graphic that shows a model's true and false positives and true and false negatives. It helps to create a visual representation of the components feeding into the metrics above.\n",
    "\n",
    "Create a confusion matrix based on your predicted values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntoJ-YG7oBIQ"
   },
   "outputs": [],
   "source": [
    "# Construct and display your confusion matrix.\n",
    "\n",
    "# Construct the confusion matrix for your predicted and test values.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Create the display for your confusion matrix.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Plot the visual in-line.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoybXyCioBIQ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about model evaluation](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/njRAP/build-an-xgboost-model-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2lqmzQ-oBIQ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Use the functions in the `metrics` module to create a confusion matrix.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi_x2zTDoBIQ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call `confusion_matrix`, passing in `y_test` and `y_pred`. Next, utilize `ConfusionMatrixDisplay()` to display your confusion matrix.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLkF5znkNk7m"
   },
   "source": [
    "**Question:** When observing your confusion matrix, what do you notice? Does this correlate to any of your other calculations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2TklKcpcjdz"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eSapvg504c8"
   },
   "source": [
    "### Visualize most important features\n",
    "\n",
    "`xgboost` has a built-in function to visualize the relative importance of the features in the model using `matplotlib`. Output and examine the feature importance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hnpvuqt204c8"
   },
   "outputs": [],
   "source": [
    "# Plot the relative feature importance of the predictor variables in your model.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nh3OwDGA04c8"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Recall the attributes that are provided once the model is fitted to training data.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daNM_TDv04c8"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Examine the `best_estimator_` attribute of your fitted model.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTrxBW9E04c8"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "To easily visualize feature importance, call the built-in `plot_importance` function `xgboost` offers on the `best_estimator_`.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyhdt0LF04c9"
   },
   "source": [
    "**Question:** Examine the feature importances outputted above. What is your assessment of the result? Did anything surprise you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bietXsnWc5Q7"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaKUSbqDW28K"
   },
   "source": [
    "### Compare models\n",
    "\n",
    "Create a table of results to compare model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6L7AgdeldsKZ"
   },
   "outputs": [],
   "source": [
    "# Create a table of results to compare model performance.\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqu9L0ip328H"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Create a DataFrame and using the `pd.DataFrame()` function. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trUO9XEHbXG6"
   },
   "source": [
    "**Question:** How does this model compare to the decision tree and random forest models you built in previous labs? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEA_YmCgg-7g"
   },
   "source": [
    "[Write your response here. Double-click (or enter) to edit.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xur2FC5xAzp0"
   },
   "source": [
    "## Considerations\n",
    "\n",
    "**What are some key takeaways you learned from this lab?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]\n",
    "\n",
    "**How would you share your findings with your team?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]\n",
    "\n",
    "**What would you share with and recommend to stakeholders?**\n",
    "\n",
    "[Write your response here. Double-click (or enter) to edit.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
